{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brew install apt-get\n",
    "apt-get update # Update apt-get repository.\n",
    "apt-get openjdk-8-jdk-headless -qq > /dev/null # Install Java.\n",
    "wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz # Download Apache Sparks.\n",
    "tar xf spark-3.1.1-bin-hadoop3.2.tgz # Unzip the tgz file.\n",
    "pip install -q findspark # Install findspark. Adds PySpark to the System path during runtime.\n",
    "pip install pyspark==3.2.1\n",
    "pip install mysql-connector-python\n",
    "apt-get -y install mysql-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
    "\n",
    "findspark.add_packages('mysql:mysql-connector-java:8.0.11')\n",
    "\n",
    "# Append the directory containing the config module to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'config')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, collect_list, explode, size, array, sort_array, struct\n",
    "\n",
    "# Append the directory containing the config module to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'config')))\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Friend Recommendations\") \\\n",
    "    .config(\"spark.jars.packages\", \"mysql:mysql-connector-java:8.0.17\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, collect_list, explode, size, array, sort_array, struct\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "url = \"jdbc:mysql://instalitedb.c1jqnrtmzqmb.us-east-1.rds.amazonaws.com:3306/instalitedb\"\n",
    "properties = {\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"rds-password\",\n",
    "    \"driver\": \"com.mysql.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "table_name = \"user_friends\"\n",
    "df = spark.read.jdbc(url=url, table=table_name, properties=properties).selectExpr(\"cast(user_id as int)\", \"cast(friend_id as int)\")\n",
    "\n",
    "# Create symmetric pairs (bi-directional relationships)\n",
    "friends = df.union(df.select(col(\"friend_id\").alias(\"user_id\"), col(\"user_id\").alias(\"friend_id\")))\n",
    "\n",
    "# Join on user_id to find friends of friends\n",
    "connections = friends.alias(\"f1\").join(friends.alias(\"f2\"), col(\"f1.friend_id\") == col(\"f2.user_id\")) \\\n",
    "    .select(col(\"f1.user_id\"), col(\"f2.friend_id\").alias(\"fof_id\")) \\\n",
    "    .where(col(\"f1.user_id\") != col(\"f2.friend_id\"))\n",
    "\n",
    "# Deduplicate and count mutual friends\n",
    "mutual_friends = connections.groupBy(\"user_id\", \"fof_id\").count()\n",
    "\n",
    "# Structure the recommendations\n",
    "recommendations_struct = mutual_friends.select(\n",
    "    \"user_id\",\n",
    "    struct(col(\"fof_id\"), col(\"count\").alias(\"mutual_friends\")).alias(\"recommendation\")\n",
    ")\n",
    "\n",
    "# Order the DataFrame by user_id and mutual_friends count descending\n",
    "ordered_recommendations = recommendations_struct.orderBy(\"user_id\", col(\"recommendation.mutual_friends\").desc())\n",
    "\n",
    "# Group by user_id and collect recommendations into a list\n",
    "final_recommendations = ordered_recommendations.groupBy(\"user_id\").agg(\n",
    "    collect_list(\"recommendation\").alias(\"recommendations\")\n",
    ")\n",
    "\n",
    "# Explode the recommendations to separate rows\n",
    "exploded_recommendations = final_recommendations.select(\n",
    "    \"user_id\",\n",
    "    explode(\"recommendations\").alias(\"recommendation\")\n",
    ")\n",
    "\n",
    "# Add rank for each recommendation within each user\n",
    "window_spec = Window.partitionBy(\"user_id\").orderBy(col(\"recommendation.mutual_friends\").desc())\n",
    "ranked_recommendations = exploded_recommendations.select(\n",
    "    \"user_id\",\n",
    "    col(\"recommendation.fof_id\").alias(\"friend_rec_id\"),\n",
    "    row_number().over(window_spec).alias(\"rank\")\n",
    ")\n",
    "\n",
    "# Show result\n",
    "ranked_recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table name in MySQL\n",
    "table_name = \"friend_recommendations\"\n",
    "\n",
    "# Write DataFrame to MySQL\n",
    "# ranked_recommendations.write.jdbc(url=url, table=table_name, mode=\"append\", properties=properties)\n",
    "\n",
    "# Write DataFrame to a staging table\n",
    "staging_table_name = \"friends_recommendation_staging\"\n",
    "ranked_recommendations.write.jdbc(url=url, table=staging_table_name, mode=\"overwrite\", properties=properties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "# Connection details\n",
    "connection = pymysql.connect(host='instalitedb.c1jqnrtmzqmb.us-east-1.rds.amazonaws.com', user=\"admin\", password='rds-password', db='instalitedb')\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql_command = \"\"\"\n",
    "        INSERT INTO friends_recommendation (user_id, friend_rec_id, rank)\n",
    "        SELECT user_id, friend_rec_id rank FROM friends_recommendation_staging\n",
    "        ON DUPLICATE KEY UPDATE\n",
    "            rank = VALUES(rank);\n",
    "        TRUNCATE TABLE friends_recommendation_staging;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "    connection.commit()\n",
    "finally:\n",
    "    connection.close()\n",
    "\n",
    "spark.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
